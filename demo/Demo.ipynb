{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Demo.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "tnDI7Hog5omz"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnDI7Hog5omz"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "# Requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nidXb-SvzyQN",
        "outputId": "099d28b9-12ca-490a-908f-eca0dcd6b3d9"
      },
      "source": [
        "!pip install svgwrite\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import sys\n",
        "from copy import deepcopy"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting svgwrite\n",
            "  Downloading svgwrite-1.4.1-py3-none-any.whl (66 kB)\n",
            "\u001b[?25l\r\u001b[K     |█████                           | 10 kB 38.5 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 20 kB 18.7 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 30 kB 15.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 40 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 51 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 61 kB 11.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 66 kB 4.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: svgwrite\n",
            "Successfully installed svgwrite-1.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCatNYia0qcI"
      },
      "source": [
        "#!/usr/bin/env python3\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "def positional_encoding(max_seq_len, dm):\n",
        "    \"\"\"\n",
        "    Calculates the positional encoding for a transformer\n",
        "    max_seq_len: integer representing the maximum sequence length\n",
        "    dm: integer representing the model depth\n",
        "    Returns: numpy.ndarray of shape (max_seq_len, dm) containing the positional\n",
        "             encoding vectors\n",
        "    \"\"\"\n",
        "    PE = np.zeros((max_seq_len, dm))\n",
        "    for row in range(max_seq_len):\n",
        "        for col in range(0, dm, 2):\n",
        "            PE[row, col] = np.sin(row / (10000 ** (col / dm)))\n",
        "            PE[row, col + 1] = np.cos(row / (10000 ** (col / dm)))\n",
        "    return PE\n",
        "\n",
        "\n",
        "def sdp_attention(Q, K, V, mask=None):\n",
        "    \"\"\"\n",
        "    Q: tensor with shape (..., seq_len_q, dk) containing the query matrix\n",
        "    K: tensor with shape (..., seq_len_v, dk) containing the key matrix\n",
        "    V: tensor with shape (..., seq_len_v, dv) containing the value matrix\n",
        "    mask: tensor that can be broadcast into (..., seq_len_q, seq_len_v)\n",
        "          containing the optional maask, or defaulted to None\n",
        "    The Preceding dimensions of Q, K, and V are the same\n",
        "    Returns: output, weights\n",
        "             output: tensor with shape (..., seq_len_q, dv) containing the dot\n",
        "                     product attention\n",
        "             weights: tensor with shape (..., seq_len_q, seq_len_v) containing\n",
        "                      the attention weights\n",
        "    \"\"\"\n",
        "    # Matmul Q and K\n",
        "    QK = tf.matmul(Q, K, transpose_b=True)\n",
        "\n",
        "    # Scale the dot product\n",
        "    dk = tf.cast(tf.shape(K)[-1], tf.float32)\n",
        "    scaled = QK / tf.math.sqrt(dk)\n",
        "\n",
        "    # Add mask if not None\n",
        "    if mask is not None:\n",
        "        scaled += mask * -1e9\n",
        "\n",
        "    # Pass scaled attention through softmax activation\n",
        "    weights = tf.nn.softmax(scaled, axis=-1)\n",
        "\n",
        "    # Matmul by value matrix for output\n",
        "    output = tf.matmul(weights, V)\n",
        "\n",
        "    return output, weights\n",
        "\n",
        "\n",
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Class to perform multi head attention\n",
        "    \"\"\"\n",
        "    def __init__(self, dm, h):\n",
        "        \"\"\"\n",
        "        dm: integer representing the model dimensionality\n",
        "        h: integer representing the number of heads\n",
        "        dm is divisible by h\n",
        "        \"\"\"\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.h = h\n",
        "        self.dm = dm\n",
        "        self.depth = dm // self.h\n",
        "        self.Wq = tf.keras.layers.Dense(dm)\n",
        "        self.Wk = tf.keras.layers.Dense(dm)\n",
        "        self.Wv = tf.keras.layers.Dense(dm)\n",
        "        self.linear = tf.keras.layers.Dense(dm)\n",
        "\n",
        "    def split_heads(self, x, batch_size):\n",
        "        \"\"\"\n",
        "        Splits the last dimension of tensor x into (h, depth)\n",
        "        Transpose the result such that the shape is\n",
        "        (batch_size, h, seq_len, depth)\n",
        "        \"\"\"\n",
        "        x = tf.reshape(x, (batch_size, -1, self.h, self.depth))\n",
        "        x = tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "        return x\n",
        "\n",
        "    def call(self, Q, K, V, mask):\n",
        "        \"\"\"\n",
        "        Q: tensor with shape (..., seq_len_q, dk) containing the query matrix\n",
        "        K: tensor with shape (..., seq_len_v, dk) containing the key matrix\n",
        "        V: tensor with shape (..., seq_len_v, dv) containing the value matrix\n",
        "        mask: always None\n",
        "        The Preceding dimensions of Q, K, and V are the same\n",
        "        Returns: output, weights\n",
        "                 output: tensor with shape (..., seq_len_q, dv) containing the\n",
        "                         dot product attention\n",
        "                 weights: tensor with shape (..., seq_len_q, seq_len_v)\n",
        "                          containing the attention weights\n",
        "        \"\"\"\n",
        "        batch_size = tf.shape(Q)[0]\n",
        "\n",
        "        # Generate query, key, and value matrices\n",
        "        Q = self.Wq(Q)\n",
        "        K = self.Wk(K)\n",
        "        V = self.Wv(V)\n",
        "\n",
        "        # Split between heads\n",
        "        Q = self.split_heads(Q, batch_size)\n",
        "        K = self.split_heads(K, batch_size)\n",
        "        V = self.split_heads(V, batch_size)\n",
        "\n",
        "        # Scaled Dot Product Attention\n",
        "        attention, weights = sdp_attention(Q, K, V, mask)\n",
        "\n",
        "        # Refit to pass through linear layer\n",
        "        attention = tf.transpose(attention, perm=[0, 2, 1, 3])\n",
        "        attention = tf.reshape(attention, (batch_size, -1, self.dm))\n",
        "        output = self.linear(attention)\n",
        "\n",
        "        return output, weights\n",
        "\n",
        "\n",
        "class DecoderBlock(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Class representation of a decoder block for a transformer\n",
        "    \"\"\"\n",
        "    def __init__(self, dm, h, hidden, drop_rate=0.1, name=None):\n",
        "        \"\"\"\n",
        "        dm: Dimensionality of the model\n",
        "        h: Number of heads\n",
        "        hidden: Number of hidden units in the fully connected layer\n",
        "        drop_rate: Dropout rate\n",
        "        \"\"\"\n",
        "        super(DecoderBlock, self).__init__()\n",
        "        if name is not None:\n",
        "            self._name = name\n",
        "        self.mha1 = MultiHeadAttention(dm, h)\n",
        "        self.dense_hidden = tf.keras.layers.Dense(\n",
        "            units=hidden,\n",
        "            activation='relu'\n",
        "        )\n",
        "        self.dense_output = tf.keras.layers.Dense(units=dm)\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = tf.keras.layers.Dropout(drop_rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(drop_rate)\n",
        "\n",
        "    def call(self, inputs, look_ahead_mask, training=False):\n",
        "        \"\"\"\n",
        "        x: tensor of shape (batch, target_seq_len, dm)containing the input to\n",
        "           the decoder block\n",
        "        training: boolean to determine if the model is training\n",
        "        look_ahead_mask: mask to be applied to the first multi head attention\n",
        "                         layer\n",
        "        Returns: tensor of shape (batch, target_seq_len, dm) containing the\n",
        "                 block's output\n",
        "        \"\"\"\n",
        "        # Pass through MHA and dropout layer\n",
        "        attn_out, _ = self.mha1(inputs, inputs, inputs, look_ahead_mask)\n",
        "        attn_out = self.dropout1(attn_out, training=training)\n",
        "\n",
        "        # Add and normalize\n",
        "        out = self.layernorm1(inputs + attn_out)\n",
        "\n",
        "        # Pass through dense layers and dropout layer\n",
        "        dense_output = self.dense_hidden(out)\n",
        "        dense_output = self.dense_output(dense_output)\n",
        "        dense_output = self.dropout2(dense_output, training=training)\n",
        "\n",
        "        # Add and normalize\n",
        "        out = self.layernorm2(out + dense_output)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Decoder(tf.keras.Model):\n",
        "    \"\"\"\n",
        "    A branched Transformer Decoder\n",
        "\n",
        "    The model uses a linear layer to bring the input feature dimension up to\n",
        "    the model's dimension before adding fixed sinusoidal positional encoding.\n",
        "\n",
        "    The model passes the encoded inputs through (Nb) decoder blocks before\n",
        "    passing their final output to two branches, of (No) and (Np) decoder blocks\n",
        "    respectively, that predict the X and Y offsets, and pen state\n",
        "    probabilities, of the next point for each given point in the sequence.\n",
        "\n",
        "    The offset branch produces an output of size (batch, sequence_len, 2),\n",
        "    where the feature dimension is [X offset, Y Offset] from the previous point.\n",
        "\n",
        "    The pen state branch produces an output of size (batch, sequence_len, 3),\n",
        "    where the feature dimension is [p0, p1, p2], each representing the\n",
        "    probabilities that the pen will be down, up, or finished, respectively.\n",
        "\n",
        "    Returns: offsets_predictions, pen_state_predictions\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 Nb,                # Number of blocks in model base\n",
        "                 No,                # Number of blocks in offset branch\n",
        "                 Np,                # Number of blocks in pen state branch\n",
        "                 dm,                # Model dimensionality\n",
        "                 h,                 # Number of heads used in attention\n",
        "                 hidden,            # Hidden layer dimenssionality\n",
        "                 max_seq_len,       # Maximum sequence length\n",
        "                 drop_rate=0.1):    # Drop rate used in dropout layers\n",
        "\n",
        "        super(Decoder, self).__init__()\n",
        "        self.Nb = Nb\n",
        "        self.No = No\n",
        "        self.Np = Np\n",
        "        self.dm = dm\n",
        "        self.projection = tf.keras.layers.Dense(dm, name='base_projection')\n",
        "        self.positional_encoding = positional_encoding(max_seq_len, dm)\n",
        "        self.dropout = tf.keras.layers.Dropout(drop_rate)\n",
        "\n",
        "        self.base_blocks = [\n",
        "            DecoderBlock(dm, h, hidden, drop_rate,\n",
        "            name=\"base_block_\" + str(n)) for n in range(Nb)\n",
        "        ]\n",
        "        self.offset_blocks = [\n",
        "            DecoderBlock(dm, h, hidden, drop_rate,\n",
        "            name=\"offset_block_\" + str(n)) for n in range(No)\n",
        "        ]\n",
        "        self.pen_blocks = [\n",
        "            DecoderBlock(dm, h, hidden, drop_rate,\n",
        "            name=\"pen_block_\" + str(n)) for n in range(Np)\n",
        "        ]\n",
        "\n",
        "        self.offset_dense = tf.keras.layers.Dense(dm, name='offset_dense')\n",
        "        self.offset_out = tf.keras.layers.Dense(2, name='offset_out')\n",
        "        self.pen_dense = tf.keras.layers.Dense(dm, name='pen_dense')\n",
        "        self.pen_out = tf.keras.layers.Dense(3, name='pen_out',\n",
        "                                             activation='softmax')\n",
        "\n",
        "    def call(self,\n",
        "             inputs,                # Input data\n",
        "             look_ahead_mask=None,  # Mask used for attention\n",
        "             training=False):       # Whether the model is training or not\n",
        "\n",
        "        seq_len = int(inputs.shape[1])\n",
        "\n",
        "        # Project to model dimension\n",
        "        x = self.projection(inputs)\n",
        "\n",
        "        # Add positional encoding and pass through dropout layer\n",
        "        x *= tf.math.sqrt(tf.cast(self.dm, 'float32'))\n",
        "        x += self.positional_encoding[:seq_len]\n",
        "        x = self.dropout(x, training=training)\n",
        "\n",
        "        # Pass through base decoder blocks\n",
        "        for block in self.base_blocks:\n",
        "            x = block(x, look_ahead_mask, training)\n",
        "\n",
        "        # Pass base output through offset branch\n",
        "        offset = x\n",
        "        for block in self.offset_blocks:\n",
        "            offset = block(offset, look_ahead_mask, training)\n",
        "        offset = self.offset_dense(offset)\n",
        "        offset = self.offset_out(offset)\n",
        "\n",
        "        # Pass base output through pen state branch\n",
        "        pen = x\n",
        "        for block in self.pen_blocks:\n",
        "            pen = block(pen, look_ahead_mask, training)\n",
        "        pen = self.pen_dense(pen)\n",
        "        pen = self.pen_out(pen)\n",
        "\n",
        "        return offset, pen\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-5QHfuK1Kpp"
      },
      "source": [
        "# Function from utils.py for sketch-rnn in the Magenta github repository\n",
        "# at https://github.com/magenta/magenta/tree/main/magenta/models/sketch_rnn\n",
        "def to_big_strokes(stroke, max_len=250):\n",
        "  \"\"\"Converts from stroke-3 to stroke-5 format and pads to given length.\"\"\"\n",
        "  # (But does not insert special start token).\n",
        "\n",
        "  result = np.zeros((max_len, 5), dtype=float)\n",
        "  l = len(stroke)\n",
        "  assert l <= max_len\n",
        "  result[0:l, 0:2] = stroke[:, 0:2]\n",
        "  result[0:l, 3] = stroke[:, 2]\n",
        "  result[0:l, 2] = 1 - result[0:l, 3]\n",
        "  result[l:, 4] = 1\n",
        "  return result\n",
        "\n",
        "def clean(data, max_length=100):\n",
        "    \"\"\"\n",
        "    Data is a np 3d array of samples in stroke-3 format\n",
        "    Removes all samples with length > max_length\n",
        "    Converts to stroke-5 and pads to max_length\n",
        "    \"\"\"\n",
        "    dataset = []\n",
        "    for sample in data:\n",
        "        if len(sample) <= max_length:\n",
        "            sample = to_big_strokes(sample, max_length)\n",
        "            dataset.append(sample)\n",
        "    dataset = np.asarray(dataset)\n",
        "    return dataset\n",
        "\n",
        "\n",
        "class Dataset:\n",
        "    \"\"\" Loads a numpy.npz file to be used for training \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 filepath,          # Path to file to load \n",
        "                 batch_size=32,     # Batch size to use\n",
        "                 max_length=250):   # Maximum sequence length per example\n",
        "\n",
        "        data = np.load(\n",
        "            filepath,\n",
        "            encoding='latin1',\n",
        "            allow_pickle=True\n",
        "        )\n",
        "\n",
        "        # Clean up dataset, removing samples over max_length\n",
        "        self.train = clean(data['train'], max_length)\n",
        "        self.valid = clean(data['valid'], max_length)\n",
        "        self.test = clean(data['test'], max_length)\n",
        "\n",
        "        # Convert to tensorflow datasets for training\n",
        "        self.train = tf.convert_to_tensor(self.train)\n",
        "        self.train = tf.data.Dataset.from_tensor_slices(list(self.train))\n",
        "        self.valid = tf.convert_to_tensor(self.valid)\n",
        "        self.valid = tf.data.Dataset.from_tensor_slices(list(self.valid))\n",
        "        self.test = tf.convert_to_tensor(self.test)\n",
        "        self.test = tf.data.Dataset.from_tensor_slices(list(self.test))\n",
        "\n",
        "        # Shuffle and batch train and valid sets\n",
        "        self.train = self.train.shuffle(max_length)\n",
        "        self.valid = self.valid.shuffle(max_length)\n",
        "        self.train = self.train.batch(batch_size)\n",
        "        self.valid = self.valid.batch(batch_size)\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mygUDwq5IZY"
      },
      "source": [
        "def train_model(Nb,           # Number of blocks in model base\n",
        "                No,           # Number of blocks in offset branch\n",
        "                Np,           # Number of blocks in pen state branch\n",
        "                dm,           # Model dimensionality\n",
        "                h,            # Number of heads used in attention\n",
        "                hidden,       # Hidden layer dimensionality\n",
        "                max_len,      # Maximum sequence length\n",
        "                batch_size,   # Batch size\n",
        "                epochs,       # Number of epochs to train for\n",
        "                filepath,     # Path to file to use for training dataset\n",
        "                verbose=1,    # 0: No printing, 1: Print loss after each epoch,\n",
        "                              # 2: Print loss every 50 epochs\n",
        "                weights=None):# Path to weights to use for continuing training\n",
        "                              # If none, model weights will be initialized\n",
        "    \"\"\"\n",
        "    Creates and trains a model used for predicting future points in an\n",
        "    unfinished drawing from Google's Quick, Draw! dataset.\n",
        "\n",
        "    The offset prediction branch is trained using Mean Squared Error loss, and\n",
        "    the pen state prediction branch is trained using Categorical Crossentropy\n",
        "    loss.\n",
        "\n",
        "    The model's weights are saved and overwritten after each epoch if they are\n",
        "    the best performing at the time.\n",
        "\n",
        "    Returns: The model, MSE loss history, CCE loss history\n",
        "    \"\"\"\n",
        "\n",
        "    # Load dataset\n",
        "    data = Dataset(filepath, batch_size=batch_size, max_length=max_len)\n",
        "    \n",
        "    # Create model\n",
        "    model = Decoder(Nb, No, Np, dm, h, hidden, max_len)\n",
        "\n",
        "    # Run a dummy set of inputs through to initialize weights\n",
        "    inputs = np.random.uniform(size=(1, max_len, 5))\n",
        "    model(inputs, None)\n",
        "\n",
        "    # Load weights if continuing training\n",
        "    if weights is not None:\n",
        "        model.load_weights(weights)\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    # Create lists of weights to apply gradients to.\n",
        "    # Done to separate loss and gradients between offset and pen state \n",
        "    # branches, while still applying both to the shared base\n",
        "    offset_weights = []\n",
        "    pen_weights = []\n",
        "    for weight in model.trainable_weights:\n",
        "        if \"base\" in weight.name:\n",
        "            offset_weights.append(weight)\n",
        "            pen_weights.append(weight)\n",
        "        if \"offset\" in weight.name:\n",
        "            offset_weights.append(weight)\n",
        "        if \"pen\" in weight.name:\n",
        "            pen_weights.append(weight)\n",
        "\n",
        "    # Loss functions, metrics, learning rate scheduler, optimizers\n",
        "    offset_loss_func = tf.keras.losses.MeanSquaredError()\n",
        "    pen_loss_func = tf.keras.losses.CategoricalCrossentropy()\n",
        "\n",
        "    pen_train_loss = tf.keras.metrics.Mean(name='pen_train_loss')\n",
        "    offset_train_loss = tf.keras.metrics.Mean(name='offset_train_loss')\n",
        "\n",
        "    learning_rate = 0.0001\n",
        "    #learning_rate = CustomSchedule(dm)\n",
        "\n",
        "    offset_optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "    pen_optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "    # Sequence length is constant throughout the dataset, so the attention\n",
        "    # mask can be made ahead of time\n",
        "    mask = 1 - tf.linalg.band_part(tf.ones((max_len - 1, max_len - 1)), -1, 0)\n",
        "\n",
        "    # Create lists to store loss histories\n",
        "    offset_losses = []\n",
        "    pen_losses = []\n",
        "\n",
        "    # High arbitrary number to begin comparing best loss to\n",
        "    prev_best = 10000\n",
        "\n",
        "    # Define training step\n",
        "    def train_step(inputs, real):\n",
        "        \"\"\" Single training step \"\"\"\n",
        "\n",
        "        # Create gradient tape and get predictions from the model\n",
        "        with tf.GradientTape(persistent=True) as tape:\n",
        "            offsets, pen_states = model(inputs, mask, True)\n",
        "\n",
        "            # Calculate losses\n",
        "            offset_loss = offset_loss_func(real[:, :, :2], offsets)\n",
        "            pen_loss = pen_loss_func(real[:, :, 2:], pen_states)\n",
        "\n",
        "        # Apply gradients to offset branch & base\n",
        "        grads = tape.gradient(offset_loss, offset_weights)\n",
        "        offset_optimizer.apply_gradients(zip(grads, offset_weights))\n",
        "\n",
        "        # Apply gradients to pen state branch & base\n",
        "        grads = tape.gradient(pen_loss, pen_weights)\n",
        "        pen_optimizer.apply_gradients(zip(grads, pen_weights))\n",
        "\n",
        "        # Update loss states\n",
        "        offset_train_loss(offset_loss)\n",
        "        pen_train_loss(pen_loss)\n",
        "\n",
        "        del tape\n",
        "\n",
        "    # Training Loop\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        # Reset loss metrics at the start of the epoch\n",
        "        offset_train_loss.reset_states()\n",
        "        pen_train_loss.reset_states()\n",
        "\n",
        "        for batch, inp in enumerate(data.train):\n",
        "\n",
        "            # Target values are input values shifted right by one step\n",
        "            train_step(inp[:, :-1], inp[:, 1:])\n",
        "\n",
        "            # Update loss histories\n",
        "            offset_losses.append(offset_train_loss.result())\n",
        "            pen_losses.append(pen_train_loss.result())\n",
        "\n",
        "            if verbose == 2:  # Print results every 50 batches\n",
        "                if batch % 50 == 0:\n",
        "                    if batch % 50 == 0:\n",
        "                        print(\"Epoch {}, batch {}: Offset Loss: {} Pen Loss {}\"\n",
        "                        .format(\n",
        "                            epoch + 1,\n",
        "                            batch,\n",
        "                            offset_train_loss.result(),\n",
        "                            pen_train_loss.result()\n",
        "                        ))\n",
        "\n",
        "        if verbose >= 1:  # Print results after each epoch\n",
        "            print(\"Epoch {}: Offset Loss: {:.4f} Pen Loss {:.4f}\".format(\n",
        "                epoch + 1,\n",
        "                offset_train_loss.result(),\n",
        "                pen_train_loss.result()\n",
        "            ))\n",
        "\n",
        "        # Save best performing weights\n",
        "        if offset_train_loss.result() < prev_best:\n",
        "            model.save_weights('50_epoch_best.h5')\n",
        "            prev_best = offset_train_loss.result()\n",
        "\n",
        "    return model, offset_losses, pen_losses\n",
        "\n",
        "\n",
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    \"\"\" Custom learning rate schedule \"\"\"\n",
        "    def __init__(self, d_model, warmup_steps=25000):\n",
        "        \"\"\" Init \"\"\"\n",
        "        super(CustomSchedule, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "        self.warmup_steps = warmup_steps\n",
        "\n",
        "    def __call__(self, step):\n",
        "        \"\"\" Call \"\"\"\n",
        "        arg1 = tf.math.rsqrt(step)\n",
        "        arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8ITDUUs08L6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4c6a5fa-df9a-485b-b809-d73280979625"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "large_model, offset_losses, pen_losses = train_model(\n",
        "    8,              # Base blocks\n",
        "    4,              # Offset blocks\n",
        "    4,              # Pen state blocks\n",
        "    128,            # Model dimensionality\n",
        "    8,              # Heads\n",
        "    512,            # Hidden units\n",
        "    100,            # Max sequence length\n",
        "    64,             # Batch size\n",
        "    0,              # Epochs\n",
        "    'cat.npz',      # File path\n",
        "    2,              # Verbosity\n",
        "    'Double size 50 epochs.h5')# Weights to load if continuing training\n",
        "\n",
        "\n",
        "small_model, offset_losses, pen_losses = train_model(\n",
        "    4,              # Base blocks\n",
        "    2,              # Offset blocks\n",
        "    2,              # Pen state blocks\n",
        "    128,            # Model dimensionality\n",
        "    8,              # Heads\n",
        "    512,            # Hidden units\n",
        "    100,            # Max sequence length\n",
        "    64,             # Batch size\n",
        "    0,              # Epochs\n",
        "    'cat.npz',      # File path\n",
        "    2,              # Verbosity\n",
        "    '160 Epochs.h5')# Weights to load if continuing training\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "base_projection (Dense)      multiple                  768       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            multiple                  0         \n",
            "_________________________________________________________________\n",
            "base_block_0 (DecoderBlock)  multiple                  198272    \n",
            "_________________________________________________________________\n",
            "base_block_1 (DecoderBlock)  multiple                  198272    \n",
            "_________________________________________________________________\n",
            "base_block_2 (DecoderBlock)  multiple                  198272    \n",
            "_________________________________________________________________\n",
            "base_block_3 (DecoderBlock)  multiple                  198272    \n",
            "_________________________________________________________________\n",
            "base_block_4 (DecoderBlock)  multiple                  198272    \n",
            "_________________________________________________________________\n",
            "base_block_5 (DecoderBlock)  multiple                  198272    \n",
            "_________________________________________________________________\n",
            "base_block_6 (DecoderBlock)  multiple                  198272    \n",
            "_________________________________________________________________\n",
            "base_block_7 (DecoderBlock)  multiple                  198272    \n",
            "_________________________________________________________________\n",
            "offset_block_0 (DecoderBlock multiple                  198272    \n",
            "_________________________________________________________________\n",
            "offset_block_1 (DecoderBlock multiple                  198272    \n",
            "_________________________________________________________________\n",
            "offset_block_2 (DecoderBlock multiple                  198272    \n",
            "_________________________________________________________________\n",
            "offset_block_3 (DecoderBlock multiple                  198272    \n",
            "_________________________________________________________________\n",
            "pen_block_0 (DecoderBlock)   multiple                  198272    \n",
            "_________________________________________________________________\n",
            "pen_block_1 (DecoderBlock)   multiple                  198272    \n",
            "_________________________________________________________________\n",
            "pen_block_2 (DecoderBlock)   multiple                  198272    \n",
            "_________________________________________________________________\n",
            "pen_block_3 (DecoderBlock)   multiple                  198272    \n",
            "_________________________________________________________________\n",
            "offset_dense (Dense)         multiple                  16512     \n",
            "_________________________________________________________________\n",
            "offset_out (Dense)           multiple                  258       \n",
            "_________________________________________________________________\n",
            "pen_dense (Dense)            multiple                  16512     \n",
            "_________________________________________________________________\n",
            "pen_out (Dense)              multiple                  387       \n",
            "=================================================================\n",
            "Total params: 3,206,789\n",
            "Trainable params: 3,206,789\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"decoder_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "base_projection (Dense)      multiple                  768       \n",
            "_________________________________________________________________\n",
            "dropout_33 (Dropout)         multiple                  0         \n",
            "_________________________________________________________________\n",
            "base_block_0 (DecoderBlock)  multiple                  198272    \n",
            "_________________________________________________________________\n",
            "base_block_1 (DecoderBlock)  multiple                  198272    \n",
            "_________________________________________________________________\n",
            "base_block_2 (DecoderBlock)  multiple                  198272    \n",
            "_________________________________________________________________\n",
            "base_block_3 (DecoderBlock)  multiple                  198272    \n",
            "_________________________________________________________________\n",
            "offset_block_0 (DecoderBlock multiple                  198272    \n",
            "_________________________________________________________________\n",
            "offset_block_1 (DecoderBlock multiple                  198272    \n",
            "_________________________________________________________________\n",
            "pen_block_0 (DecoderBlock)   multiple                  198272    \n",
            "_________________________________________________________________\n",
            "pen_block_1 (DecoderBlock)   multiple                  198272    \n",
            "_________________________________________________________________\n",
            "offset_dense (Dense)         multiple                  16512     \n",
            "_________________________________________________________________\n",
            "offset_out (Dense)           multiple                  258       \n",
            "_________________________________________________________________\n",
            "pen_dense (Dense)            multiple                  16512     \n",
            "_________________________________________________________________\n",
            "pen_out (Dense)              multiple                  387       \n",
            "=================================================================\n",
            "Total params: 1,620,613\n",
            "Trainable params: 1,620,613\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74E7ysgRZ2sc"
      },
      "source": [
        "# libraries required for visualisation:\n",
        "import os\n",
        "import svgwrite\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from IPython.display import SVG, display\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "# import data_Manager\n",
        "import math\n",
        "from matplotlib import animation\n",
        "\n",
        "# data_Manager = Data\n",
        "# set numpy output to something sensible\n",
        "np.set_printoptions(precision=8, edgeitems=6, linewidth=200, suppress=True)\n",
        "\n",
        "\n",
        "def get_bounds(data, factor=10):\n",
        "    \"\"\"Return bounds of data.\"\"\"\n",
        "    min_x = 0\n",
        "    max_x = 0\n",
        "    min_y = 0\n",
        "    max_y = 0\n",
        "\n",
        "    abs_x = 0\n",
        "    abs_y = 0\n",
        "    for i in range(len(data)):\n",
        "        x = float(data[i, 0]) / factor\n",
        "        y = float(data[i, 1]) / factor\n",
        "        abs_x += x\n",
        "        abs_y += y\n",
        "        min_x = min(min_x, abs_x)\n",
        "        min_y = min(min_y, abs_y)\n",
        "        max_x = max(max_x, abs_x)\n",
        "        max_y = max(max_y, abs_y)\n",
        "\n",
        "    return (min_x, max_x, min_y, max_y)\n",
        "\n",
        "\n",
        "def slerp(p0, p1, t):\n",
        "    \"\"\"Spherical interpolation.\"\"\"\n",
        "    omega = np.arccos(np.dot(p0 / np.linalg.norm(p0), p1 / np.linalg.norm(p1)))\n",
        "    so = np.sin(omega)\n",
        "    return np.sin((1.0 - t) * omega) / so * p0 + np.sin(t * omega) / so * p1\n",
        "\n",
        "\n",
        "def lerp(p0, p1, t):\n",
        "    \"\"\"Linear interpolation.\"\"\"\n",
        "    return (1.0 - t) * p0 + t * p1\n",
        "\n",
        "\n",
        "def to_normal_strokes(big_stroke):\n",
        "    \"\"\"Convert from stroke-5 format to stroke-3.\"\"\"\n",
        "    l = 0\n",
        "    for i in range(len(big_stroke)):\n",
        "        if big_stroke[i, 4] > 0:\n",
        "            l = i\n",
        "            break\n",
        "    if l == 0:\n",
        "        l = len(big_stroke)\n",
        "    result = np.zeros((l, 3))\n",
        "    result[:, 0:2] = big_stroke[0:l, 0:2]\n",
        "    result[:, 2] = big_stroke[0:l, 3]\n",
        "    return result\n",
        "\n",
        "\n",
        "# little function that displays vector images and saves them to .svg\n",
        "def draw_strokes(data, factor=0.2, svg_filename = '/tmp/sketch_rnn/svg/sample.svg'):\n",
        "    # data = data_Manager.to_normal_strokes(data)\n",
        "    data = to_normal_strokes(data)\n",
        "    min_x, max_x, min_y, max_y = get_bounds(data, factor)\n",
        "    dims = (50 + max_x - min_x, 50 + max_y - min_y)\n",
        "    dwg = svgwrite.Drawing(svg_filename, size=dims)\n",
        "    dwg.add(dwg.rect(insert=(0, 0), size=dims,fill='white'))\n",
        "    lift_pen = 1\n",
        "    abs_x = 25 - min_x \n",
        "    abs_y = 25 - min_y\n",
        "    p = \"M%s,%s \" % (abs_x, abs_y)\n",
        "    command = \"m\"\n",
        "    for i in range(len(data)):\n",
        "        if (lift_pen == 1):\n",
        "            command = \"m\"\n",
        "        elif (command != \"l\"):\n",
        "            command = \"l\"\n",
        "        else:\n",
        "            command = \"\"\n",
        "        x = float(data[i,0])/factor\n",
        "        y = float(data[i,1])/factor\n",
        "        lift_pen = data[i, 2]\n",
        "        p += command+str(x)+\",\"+str(y)+\" \"\n",
        "    the_color = \"black\"\n",
        "    stroke_width = 3\n",
        "    dwg.add(dwg.path(p).stroke(the_color,stroke_width).fill(\"none\"))\n",
        "    dwg.save()\n",
        "    display(SVG(dwg.tostring()))\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Function for animate drawing. \n",
        "taken from \n",
        "https://colab.research.google.com/github/zaidalyafeai/Notebooks/blob/master/Strokes_QuickDraw.ipynb#scrollTo=0ABX6O4kYwYS\n",
        "\"\"\"\n",
        "def create_animation(drawing, fps = 30, idx = 0, lw = 5): \n",
        "  \n",
        "  seq_length = 0 \n",
        "  \n",
        "  xmax = 0 \n",
        "  ymax = 0 \n",
        "  \n",
        "  xmin = math.inf\n",
        "  ymin = math.inf\n",
        "  \n",
        "  #retreive min,max and the length of the drawing  \n",
        "  for k in range(0, len(drawing)):\n",
        "    x = drawing[k][0]\n",
        "    y = drawing[k][1]\n",
        "\n",
        "    seq_length += len(x)\n",
        "    xmax = max([max(x), xmax]) \n",
        "    ymax = max([max(y), ymax]) \n",
        "    \n",
        "    xmin = min([min(x), xmin]) \n",
        "    ymin = min([min(y), ymin]) \n",
        "    \n",
        "  i = 0 \n",
        "  j = 0\n",
        "  \n",
        "  # First set up the figure, the axis, and the plot element we want to animate\n",
        "  fig = plt.figure()\n",
        "  ax = plt.axes(xlim=(xmax+lw, xmin-lw), ylim=(ymax+lw, ymin-lw))\n",
        "  ax.set_facecolor(\"white\")\n",
        "  line, = ax.plot([], [], lw=lw)\n",
        "\n",
        "  #remove the axis \n",
        "  ax.grid = False\n",
        "  ax.set_xticks([])\n",
        "  ax.set_yticks([])\n",
        "  \n",
        "  # initialization function: plot the background of each frame\n",
        "  def init():\n",
        "      line.set_data([], [])\n",
        "      return line, \n",
        "\n",
        "  # animation function.  This is called sequentially\n",
        "  def animate(frame):    \n",
        "    nonlocal i, j, line\n",
        "    x = drawing[i][0]\n",
        "    y = drawing[i][1]\n",
        "    line.set_data(x[0:j], y[0:j])\n",
        "    \n",
        "    if j >= len(x):\n",
        "      i +=1\n",
        "      j = 0 \n",
        "      line, = ax.plot([], [], lw=lw)\n",
        "      \n",
        "    else:\n",
        "      j += 1\n",
        "    return line,\n",
        "  \n",
        "  # call the animator.  blit=True means only re-draw the parts that have changed.\n",
        "  anim = animation.FuncAnimation(fig, animate, init_func=init,\n",
        "                                 frames= seq_length + len(drawing), blit=True)\n",
        "  plt.close()\n",
        "  \n",
        "  # save the animation as an mp4.  \n",
        "  anim.save(f'video.mp4', fps=fps, extra_args=['-vcodec', 'libx264'])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGJwksLejbIq"
      },
      "source": [
        "# Load dataset\n",
        "def to_big_strokes(stroke, max_len=250):\n",
        "  \"\"\"Converts from stroke-3 to stroke-5 format and pads to given length.\"\"\"\n",
        "  # (But does not insert special start token).\n",
        "\n",
        "  result = np.zeros((max_len, 5), dtype=float)\n",
        "  l = len(stroke)\n",
        "  assert l <= max_len\n",
        "  result[0:l, 0:2] = stroke[:, 0:2]\n",
        "  result[0:l, 3] = stroke[:, 2]\n",
        "  result[0:l, 2] = 1 - result[0:l, 3]\n",
        "  result[l:, 4] = 1\n",
        "  return result\n",
        "\n",
        "def clean(data, max_length=100):\n",
        "    \"\"\"\n",
        "    Data is a np 3d array of samples in stroke-3 format\n",
        "    Removes all samples with length > max_length\n",
        "    Converts to stroke-5 and pads to max_length\n",
        "    \"\"\"\n",
        "    dataset = []\n",
        "    for sample in data:\n",
        "        if len(sample) <= max_length:\n",
        "            sample = to_big_strokes(sample, max_length)\n",
        "            dataset.append(sample)\n",
        "    dataset = np.asarray(dataset)\n",
        "    return dataset\n",
        "\n",
        "def create_mask(batch_size, seq_len):\n",
        "        \"\"\"\n",
        "        Creates the look mask for attention in the decoder\n",
        "        seq_len: Length of the sequence for which to make the mask\n",
        "        \"\"\"\n",
        "        \n",
        "        mask = 1 - tf.linalg.band_part(tf.ones((1, 1, seq_len, seq_len)), -1, 0)\n",
        "        return mask\n",
        "\n",
        "\n",
        "def predict(model, input):\n",
        "    # loop until max seq length, or drawing is finished\n",
        "    inputs = input[np.newaxis, :]\n",
        "    while inputs[0, -1, -1] != 1 and inputs.shape[1] < 100:\n",
        "        mask = create_mask(1, inputs.shape[1])\n",
        "        offsets, pen_states = model(inputs, mask)\n",
        "        offsets = np.round(offsets)\n",
        "        pen_states = np.round(pen_states)\n",
        "        pred = np.concatenate((offsets[0, -1], pen_states[0, -1]))\n",
        "        inputs = np.concatenate((inputs, pred.reshape(1, 1, 5)), axis=1)\n",
        "\n",
        "    return inputs[0]\n",
        "\n",
        "data = np.load('cat.npz', encoding='latin1', allow_pickle=True)\n",
        "data = clean(data['test'], 100)\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hP0VicY76HbK"
      },
      "source": [
        "# Demos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7HcIUSTV6uh"
      },
      "source": [
        "# Full circle input\n",
        "\n",
        "input = deepcopy(data[0, :18])\n",
        "\n",
        "complete = predict(large_model, input[:18])\n",
        "\n",
        "input[:, :2] /= 3\n",
        "complete[:, :2] /= 3\n",
        "\n",
        "draw_strokes(input[:18], svg_filename='input.svg')\n",
        "draw_strokes(complete, svg_filename=\"cat.svg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiZGR_jFxRYd"
      },
      "source": [
        "# Half circle input\n",
        "\n",
        "input = deepcopy(data[0, :11])\n",
        "\n",
        "complete = predict(large_model, input[:18])\n",
        "\n",
        "input[:, :2] /= 3\n",
        "complete[:, :2] /= 3\n",
        "\n",
        "draw_strokes(input[:11], svg_filename='input.svg')\n",
        "draw_strokes(complete, svg_filename=\"cat.svg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4L0FTLA94fW"
      },
      "source": [
        "# Start from ears\n",
        "\n",
        "drawing = deepcopy(data[21])\n",
        "\n",
        "input = drawing[:15]\n",
        "\n",
        "complete = predict(large_model, input)\n",
        "\n",
        "drawing[:, :2] /= 3\n",
        "complete[:, :2] /= 3\n",
        "\n",
        "draw_strokes(input, svg_filename=\"cat.svg\")\n",
        "draw_strokes(complete, svg_filename=\"cat.svg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woHFru4f0mkp"
      },
      "source": [
        "# Generate from nothing\n",
        "\n",
        "input = np.asarray([[0, 0, 1, 0, 0]])\n",
        "\n",
        "complete = predict(small_model, input)\n",
        "\n",
        "complete[:, :2] /= 3\n",
        "\n",
        "draw_strokes(complete, svg_filename=\"cat.svg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJ6pHPHg7DL6"
      },
      "source": [
        "# Comparison to full drawing\n",
        "\n",
        "drawing = deepcopy(data[2010])\n",
        "\n",
        "input = drawing[:20]\n",
        "\n",
        "complete = predict(large_model, input)\n",
        "\n",
        "drawing[:, :2] /= 3\n",
        "complete[:, :2] /= 3\n",
        "\n",
        "draw_strokes(drawing, svg_filename=\"cat.svg\")\n",
        "draw_strokes(input, svg_filename=\"cat.svg\")\n",
        "draw_strokes(complete, svg_filename=\"cat.svg\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}